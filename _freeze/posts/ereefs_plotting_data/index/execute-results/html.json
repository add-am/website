{
  "hash": "54675300ddd33a5b8f7e857368ba8fab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Creating Beautiful Plots using eReefs Data\"\ndate: \"05/23/2025\"\nabstract-title: \"ABSTRACT\"\nabstract: \"In this blog I demonstrate how you can make beautiful plots in R using example data extracted from the eReefs platform. You can also follow along with any of your own data.\"\nimage: \"image.png\"\nformat: html\ntitle-block-banner: true #This is our banner\ninclude-after-body: \"../../html/html_footer.html\" #This is our footer\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n# Introduction\n\nIn this blog we are going to learn how to create some visually interesting plots in R. The package we are going to be using is ggplot2, and the data we are going to be using is from eReefs. If you are interested in getting an exact copy of the data I recommend you check out my other blog; [The Extraction of Highly Specialised Modeled Data from eReefs](../ereefs_extracting_data/index.qmd), however you can still follow along just fine using your own data if it shares a similar format. Once you have completed this blog, I also highly recommend you check out my blog about [Mapping eReefs Data](../ereefs_mapping_data/index.qmd), as this blog uses exactly the same dataset and explores its' spatial aspects.\n\n# Data\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nThe first thing we want to do is load in the example data that we are going to use for this blog. This data comes in a raster format, and was extracted from eReefs. There are few steps to loading it in proper - these are explained in more detail in my other blog.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#load in the example data\nexample_data <- read_stars(\"example_data.nc\")\n\n#load vector of time values\ntime_vals <- readRDS(\"time_vector.rds\")\n\n#merge \"attributes\" (time) back together\nexample_data <- merge(example_data)\n\n#update time dimension values and names\nexample_data <- example_data |> \n  st_set_dimensions(3, time_vals,\n                    names = c(\"x\", \"y\", \"time\"))\n  \n#then update the attribute name\nexample_data <- setNames(example_data, \"Chla\")\n```\n:::\n\n\n\n\n## Converting to Tabular Format\n\nOnce we have the raster data we then need to convert it to a tabular format so it can be used by our `ggplot2` functions. There is a very handy function for this called `st_as_sf()` from the `stars` package that converts stars objects into sf objects. Sf objects are essentially tables with an extra column for spatial information, we can then convert the sf object to a \"normal\" table by simply removing the column with the extra spatial information.\n\n:::{.callout-note}\nSf objects (from the `sf` package), and stars objects (from the `stars` package) are designed to work together as the packages were written by the same author. Thank god for that guy right!\n:::\n\nThe `st_as_sf()` function has a few key arguments;\n\n - x (this is the stars object)\n - as_points (should each raster cell become a polygon (F) or a point (T)) - I usually prefer polygons\n - merge (should cells with equal values be merged? Yes (T) or No (F)) - I usually say no, as this can mess with statistics based on cell count\n - long (should the table be wide or long) - ggplot loves long data, so I usually set this to TRUE\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#convert data to a simple feature object\nsf_data <- st_as_sf(example_data, as_points = F, merge = F, long = T)\n  \n#drop the geometry column from the data\nsf_data <- sf_data |>\n  st_drop_geometry()\n```\n:::\n\n\n\n\n## Exploring the Data\n\nOkay, the data has been loaded in, and converted to tabular format. Let's take a quick look at what we are dealing with. This data has 161 rows and 179 columns. The column names are time and Chla:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#view the first few rows of the data\nhead(sf_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 time       Chla\n1 2020-07-01 02:00:00 0.07818966\n2 2020-07-01 02:00:00 0.07410832\n3 2020-07-01 02:00:00 0.07653029\n4 2020-07-01 02:00:00 0.08475932\n5 2020-07-01 02:00:00 0.07026779\n6 2020-07-01 02:00:00 0.07251479\n```\n\n\n:::\n:::\n\n\n\n\nIf we ordered this data by date we would see that there are several hundred rows of data that belong to the exact same date and time. This is because the original source of this data was a spatial file - it had a grid of values for each date and time:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#order the first few rows by date\nhead(arrange(sf_data, time))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 time       Chla\n1 2020-07-01 02:00:00 0.07818966\n2 2020-07-01 02:00:00 0.07410832\n3 2020-07-01 02:00:00 0.07653029\n4 2020-07-01 02:00:00 0.08475932\n5 2020-07-01 02:00:00 0.07026779\n6 2020-07-01 02:00:00 0.07251479\n```\n\n\n:::\n:::\n\n\n\n\nThe value column is the concentration of chlorophyll a in the water column, measured in micrograms per litre. Let's update that.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#rename the data column\nsf_data <- rename(sf_data, \"Chla (ug/L)\" = \"Chla\")\n```\n:::\n\n\n\n\nAnd to keep things consistent we will capitalise \"Time\" for the time column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf_data <- rename(sf_data, \"Time\" = \"time\")\n\n#view the first few rows of data\nhead(sf_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Time Chla (ug/L)\n1 2020-07-01 02:00:00  0.07818966\n2 2020-07-01 02:00:00  0.07410832\n3 2020-07-01 02:00:00  0.07653029\n4 2020-07-01 02:00:00  0.08475932\n5 2020-07-01 02:00:00  0.07026779\n6 2020-07-01 02:00:00  0.07251479\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nPlease note that it is generally bad form to include spaces in your column names, but I am doing it to reduce the code needed for the plotting section. You will see I have to refer to the column name using ticks (``) to make the ggplot code work because of the space in the column name.\n:::\n\n# Plotting\n\nDue to our cursory exploration of the data we already know a few things:\n\n - There is a lot of data\n - The data has a time element\n - There are multiple data points per time step\n - Values are the concentration of chlorophyll a, if you are not an environmental scientist this means the data is continuous, and should not contain negative values.\n \n## Distribution and Log Transformation\n\nHowever what we don't know is about the distribution of the data. Below is a histogram of our data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a basic histogram plot of the data\nggplot(sf_data) +\n  geom_histogram(aes(x = `Chla (ug/L)`), \n                 bins = 150,\n                 fill = \"#00252A\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nClearly this data is heavily right skewed. Although we wont be doing any statistical analysis this distribution will still impact how our plot looks. So to make things a bit nice we will look at the data with a log 10 transformation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a histogram plot of the data on a log10 scale\nggplot(sf_data) +\n  geom_histogram(aes(x = `Chla (ug/L)`), \n                 bins = 150,\n                 fill = \"#8E3B46\") +\n  scale_x_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nYup, using a log10 scale will likely help us get a better visual representation of the data.\n\nNow, knowing a bit more abut the distribution lets consider what kind of plot we want to make. Of course it is up to you, but I know that when I see a time variable and a whole bunch of continuous values, I am thinking lines and/or dot plots.\n\nIn its most basic form here is a dot plot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#creat a basic dot plot of the data\nggplot(sf_data) +\n  geom_point(aes(x = Time, y = `Chla (ug/L)`), \n             color =  \"#E6AA04\") +\n  scale_y_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nA few things to note:\n\n - As we have already covered, there is a shit ton of data and actually plotting all the points takes several minutes (boring).\n - It looks like there are some trends but it is a bit hard to tell, particularly because the number of points makes it difficult to identify areas of high, mid, or low density that might affect the trends\n\nFor the first point, a simple solution is to take a random subset of data to make plotting more efficient. For the second point, this will in part be fixed by the sub sampling, but we will also be adding extra visuals to this plot as we go along.\n\n## Subsetting Data\n\nTo do our sub-setting we will use the `slice_sample()` function. To ensure that we get the same number of randomly sampled points from each time step (day) we will make sure to first group our data by the Time column. In summary we want to randomly select 150 data points from each day - still quite a lot.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#get a random subset of data, ensuring an equal sample is taken from each day\nsf_data_subset <- sf_data |> \n  group_by(Time) |> \n  slice_sample(n = 150) |> \n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creat a basic dot plot of the data\nggplot(sf_data_subset) +\n  geom_point(aes(x = Time, y = `Chla (ug/L)`), \n             color =  \"#E6AA04\") +\n  scale_y_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\nAwesome, right away we can see that there appears to be a downtrend in concentration values around the middle of the time series before the values then increase again towards the end of the graph. It is easier to see this using this plot because we can see that there is a lower density of points in the middle of the plot near the top, where as even with the random sampling there is still a very high density of points in the middle of the plot near the bottom. It should be noted that it is theoretically possible the areas of high and low density are a product of the random sampling, but that is highly unlikely.\n\n## Additional Visuals\n\nSomething that will help us determine with greater precision how the data trends over time, would be a nice line that follows the daily mean. We will calculate this line using the full dataset to make 100% sure of the trend we spotted above.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#calculate a daily mean value\nsf_data_daily_mean <- sf_data |> \n  group_by(Time) |> \n  summarise(`Chla (ug/L)` = mean(`Chla (ug/L)`))\n\n\n#create a basic dot plot plus daily mean line\nggplot() +\n  geom_point(data = sf_data_subset, \n             aes(x = Time, y = `Chla (ug/L)`), \n             color = \"#E6AA04\") +\n  geom_line(data = sf_data_daily_mean, \n            aes(x = Time, y = `Chla (ug/L)`), \n            color = \"#00252A\",\n            lwd = 1) +\n  scale_y_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\nThis line confirms that the values do indeed decrease towards the middle of the time series before increasing again towards the end of the graph, but the line is a bit ugly no? A common replacement in this scenario is to use a Generalized Additive Model (GAM) which creates a smoothing spline that also reveals trends but is not so harsh. Noting that the GAM makes use of the multiple samples per day to achieve the desired results:  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a basic dot plot plus GAM line\nggplot() +\n  geom_point(data = sf_data_subset, \n             aes(x = Time, y = `Chla (ug/L)`), \n             color = \"#E6AA04\") +\n  geom_smooth(data = sf_data,\n              aes(x = Time, y = `Chla (ug/L)`), \n              method = \"gam\", \n              formula = y ~ s(x), \n              color = \"#00252A\",\n              se = F) +\n  scale_y_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\nSomething else of interest with time series data is how things are doing relative to a long-term mean. This long-term mean might be an annual mean, or a mean of all the available data going several years back, or a mean of some historical reference period. For us, we will just look at the annual mean:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#calculate group mean to use for the yintercept line from the full dataset\nannual_mean <- sf_data |>\n  summarise(`Mean Chla (ug/L)` = mean(`Chla (ug/L)`, na.rm = T)) |> \n  as.numeric() |> \n  round(4)\n\n#create a more sophisticated plot\nggplot() +\n  geom_point(data = sf_data_subset, \n             aes(x = Time, y = `Chla (ug/L)`), \n             color = \"#E6AA04\") +\n  geom_hline(yintercept = annual_mean,\n             colour = \"#628395\",\n             lwd = 1.3) +\n  geom_smooth(data = sf_data,\n              aes(x = Time, y = `Chla (ug/L)`), \n              method = \"gam\", \n              formula = y ~ s(x), \n              color = \"#00252A\",\n              se = F) +\n  scale_y_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\nAs expected, the smoothed GAM line fluctuates above and below the annual mean. You might initially think that the GAM line goes waaaay below the mean compared to how much it goes above the mean and that surely the mean isn't correct, but remember this is all visualised with a log10 y axis.\n\nThe next thing I would like to add is some sort of visual cue to signify season. In the Townsville region (where we are currently looking at the data) there are only two season; \"wet\" and \"dry\". This is loosely associated with summer and winter, with hundreds to thousands of millimeters of rain falling in summer and often less than one hundred millimeters falling across all of winter. The reason we care about rainfall is that it is one of the most significant drivers of chlorophyll a concentrations in the ocean. The rain on land brings lots of nutrients down the rivers and out onto the reef - nutrients which phytoplankton consume and then produce chlorophyll a (simplified explanation).The exact cut-off dates we will use for the wet season/dry season are March and October.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#assign either the wet or dry season to each row of data\nsf_data_subset <- sf_data_subset |> \n  mutate(Season = case_when(month(Time) > 4 & month(Time) < 11 ~ \"Dry\", T ~ \"Wet\"))\n  \n#create a more sophisticated plot\nggplot() +\n  geom_point(data = sf_data_subset, \n             aes(x = Time, y = `Chla (ug/L)`, \n                 color = Season)) +\n  geom_hline(yintercept = annual_mean,\n             colour = \"#628395\",\n             lwd = 1.3) +\n  scale_color_manual(values = c(\"#E6AA04\", \"#8E3B46\")) +\n  geom_smooth(data = sf_data,\n              aes(x = Time, y = `Chla (ug/L)`), \n              method = \"gam\", \n              formula = y ~ s(x), \n              color = \"#00252A\",\n              se = F) +\n  scale_y_log10() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\nIt is interesting to see that there is a clear relationship visible between season and chlorophyll a concentration. This graph suggests there is a sort of \"recharge\" and \"use\" cycle occurring. Where chlorophyll a reach a maximum concentration right after the end of the wet season, before being \"used up\" over the dry season and requiring a \"recharge\" by the following wet season.\n\nThere is only one more thing I would like to add to this plot, and it is mainly due to personal preference. I would like to overlay a violin plot to further highlight the distribution of the data we are dealing with. Specifically, it will highlight any regions of the plot in which large amounts of data are concentrated, as well as any spots that are particularly skewed. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#mutate the date column back into an actual date variable\nsf_data_subset <- sf_data_subset |> \n  mutate(Time = as.Date(Time))\n\n#do the same for the full dataset\nsf_data <- sf_data |> \n  mutate(Time = as.Date(Time))\n\n#create a more sophisticated plot\nggplot() +\n  geom_point(data = sf_data_subset, \n             aes(x = Time, y = `Chla (ug/L)`, \n                 color = Season)) +\n  geom_hline(yintercept = annual_mean,\n             colour = \"#628395\",\n             lwd = 1.3) +\n  scale_color_manual(values = c(\"#E6AA04\", \"#8E3B46\")) +\n  geom_smooth(data = sf_data,\n              aes(x = Time, y = `Chla (ug/L)`), \n              method = \"gam\", \n              formula = y ~ s(x), \n              color = \"#00252A\",\n              se = F) +\n  geom_violin(data = sf_data_subset,\n              aes(x = Time, y = `Chla (ug/L)`),\n              alpha = 0.4, \n              color = \"Black\") +\n  scale_y_log10() +\n  scale_x_date(breaks = pretty_breaks(6)) +\n  labs(x = \"Time\", y = \"Chla (ug/L) (Log10 Scale)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\nAnd there you have it, a fairly nice looking singular dot plot. It contains a heck of a lot of information without being too crowed (in my opinion). Some extensions you could play around with for this plot could be downloading several years of data and faceting by year, comparing different water quality indicators, or even comparing different locations around the reefs.\n\n# Caveats\n\nYou may find that the visuals in these plots are not for you, that's okay! Just because I say they look good doesn't mean you have to think that. Play around with colours, do a deep dive on [ggplot2](https://ggplot2.tidyverse.org/) options, experiment with your own ideas and find a style that works for you. There are also plenty of guide around design rules if you are particularly interested, such as this one by [Tableau](https://www.tableau.com/visualization/data-visualization-best-practices).\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}