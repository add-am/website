[
  {
    "objectID": "posts/tmap_migrating_to_v4/index.html",
    "href": "posts/tmap_migrating_to_v4/index.html",
    "title": "Migrating to Version 4 of the tmap R Package",
    "section": "",
    "text": "1 Introduction\nThe tmap package is one of my all time favourite R packages, and this latest update only solidified this opinion. I highly recommend that you check out the main page here, and take the time to read over some of the documents in each of the tabs.\nAs of 2025-01-27, tmap version 4.0 was released, and with it came some BIG changes. The authors have done a great job making sure that the update is backwards compatible with your current code, however moving forward it is very important to start doing things the “new” way. One of the most impactful in my opinion is changes to the syntax used with a lot of the core functions. This new syntax makes things easier to understand, cleaner, and provides greater flexibility in the creation of your maps. New datasets have also been added for demonstration purposes as well as the ability to extent tmap (to do things like map very unique spatial data types, or creating map overlays in a 3D environment).\n\n\n2 How things Used to Look\n\n\n\n\n\n\nNote\n\n\n\nFor the purposes of this blog I will assume a basic understanding of the tmap package.\n\n\nRight, so in version 3.0, how did things look? Well, if I’m honest they looked a little messy. Unfortunately I can’t provide the datasets I used in my day-to-day, but lets roughly recreate how my code would have looked using some example data.\n\n\nCode\nlibrary(tmap)\nlibrary(dplyr)\n\ndata &lt;- NLD_muni |&gt; \n  filter(province == \"Fryslan\")#|&gt; \n # slice_head(n = 10)\n\ntm_shape(data) +\n  tm_polygons(col = \"name\", border.col = \"black\", alpha = 0.8, palette = \"Pastel1\", legend.show = T) +\n  tm_text(\"name\", shadow = T, auto.placement = T, size = 0.6) +\n  tm_layout(legend.bg.color = \"white\", legend.frame = \"black\", asp = 1.1,\n            legend.outside = TRUE, legend.outside.position = \"top\")\n\n\n\n\n\n\n\n\n\nCode\n#map &lt;- tm_shape(seagrass, is.master = T) +\n#  tm_borders(alpha = 0) +\n#  tm_shape(qld) +\n#  tm_polygons(col = \"grey80\") +\n#  tm_shape(dt_background) +\n#  tm_polygons(col = \"grey90\", border.col = \"black\") +\n#  tm_shape(dt_marine) +\n#  tm_polygons(col = \"Geographic Area: All\", border.col = \"black\", alpha = 0.3, palette = \"Pastel1\", legend.show = T) +\n#  water_map +\n#  tm_shape(tsv) +\n#  tm_symbols(size = 0.3, col = \"white\", border.col = \"black\", border.lwd = 1, shape = 23) +\n#  tm_text(\"PlaceName\", shadow = T, auto.placement = T, size = 0.6) +\n#  tm_shape(seagrass) +\n#  tm_polygons(col = \"Meadow ID\", palette = \"Set3\", border.col = \"black\", legend.show = F) +\n#  tm_text(\"Meadow ID\", shadow = T, auto.placement = T, size = 1.5) +\n#  tm_layout(legend.bg.color = \"white\", legend.frame = \"black\", asp = 1.1,\n#            legend.position = c(\"left\", \"bottom\"))\n\n\nMain points to hit\n\ndemonstrate I can do mapping\nshow some things i used to do\nshow how i have updated those things\n\nHere is an example of what i used to do:\n\n\nCode\n #build on these two layers with customization\n\n\nthings i have noticed\n\nis.master is now is.main. doesn’t seem to be a note of that one\norganisation is much cleaner now, all the fill.xyz can be put together and it is easy to spot which arguments relate to one another\ntext shadow seems to be a legacy aspect\nsetting colours and styles makes much more sense now. doing the cat vs cont, and setting the palette etc.\nmy preferred lay out has changed. I now like to list each argument under the next - helps with grouping but does make code have more lines"
  },
  {
    "objectID": "posts/learning_to_create_custom_functions/index.html",
    "href": "posts/learning_to_create_custom_functions/index.html",
    "title": "Learning To Create Your Own Custom Functions",
    "section": "",
    "text": "If you’re anything like me, when you first thought of creating your own custom functions in R it felt so wildly out of your comfort zone that you decided against it. They seemed big and scary, and only something the “really good” R coders did. The reality is far from that, and I hope this post does something to dissuade that fear and push you to start creating your own functions. Below, I’d like to discuss the essentials:\n\nWhat are functions really?\nWhy you should consider making custom functions.\nHow you can make your own functions.\nSome compelling reasons for making your own functions.\n\n\n\n\n\n\n\nNote\n\n\n\nWant to see one of my custom functions in action? I’ve already written an entire blog post about a function I use almost every day! Check it out here, it is all about cleaning and organizing dataframes (yes, I am aware that sounds boring, I promise its not)."
  },
  {
    "objectID": "posts/learning_to_create_custom_functions/index.html#an-example-of-a-useful-custom-function",
    "href": "posts/learning_to_create_custom_functions/index.html#an-example-of-a-useful-custom-function",
    "title": "Learning To Create Your Own Custom Functions",
    "section": "3.1 An Example of A Useful Custom Function",
    "text": "3.1 An Example of A Useful Custom Function\nAnyway, lets actually create our own (useful) function. When I first understood how to create a function I was super excited to get started, but I quickly realized that I didn’t actually have a good reason to write a function. I find this is the case with a lot of intermediate coders, you might know the theory, but then finding places to implement it presents a whole new challenge. So lets refresh and hopefully come up with some good ideas:\n\nFunctions are bits of code that are used lots - is there anything code you have written that you have used more than once?\nFunctions usually do one thing really well - your first function doesn’t have to change the world!\nThere are thousands of functions already out there - the “best” problems probably already have functions written for them, focus on problems specific to your niche of work to find gaps.\n\nUsing these points, here are some ideas relevant to me (I encourage you to think of your own):\n\nA function that cleans tables how I specifically like them to look (see here).\nA function that run specific statistical calculates I use for my scientific reports.\nA function that calculates landuse change by class (check out my long-form projects to read about this one).\nA function that calculates important summary statistics about fish observations.\n\nFor demonstration purposes, lets learn together how to create that fourth function; calculating summary stats for fish observation data. First, here is some example data that I made up. It has observation counts for three different fish species across four different locations:\n\n\nCode\n#read in the example dataset\nfish_obs_df &lt;- read.csv(\"fish_obs_df.csv\")\n\n#view the dataframe\ncond_form_tables(head(fish_obs_df, 10))\n\n\n\n\nLocationSpeciesObservations\n\nLocation DSpecies 20\n\nLocation BSpecies 217\n\nLocation ASpecies 39\n\nLocation ASpecies 213\n\nLocation DSpecies 19\n\nLocation CSpecies 24\n\nLocation DSpecies 215\n\nLocation CSpecies 38\n\nLocation BSpecies 310\n\nLocation ASpecies 29\n\n\n\n\n\n\nCode\n#plot the data\nggplot(fish_obs_df) +\n  geom_density(aes(x=Observations, color = Species, fill = Species), bw = 0.4, alpha = 0.5) +\n  scale_fill_manual(values = c(\"#e6aa04\", \"#00252A\", \"#8E3B46\")) +\n  scale_colour_manual(values = c(\"#e6aa04\", \"#00252A\", \"#8E3B46\")) +\n  theme_bw() +\n  facet_wrap(~Location)\n\n\n\n\n\n\n\n\n\nThe data looks fairly standard. Normally, we probably then proceed to calculate some basic stats like the mean, median, min, max, etc. So lets do that:\n\n\nCode\n#generic summary stats\nsummary_table &lt;- fish_obs_df |&gt; \n  group_by(Location, Species) |&gt; \n  summarise(Mean = round(mean(Observations),2),\n            Median = median(Observations),\n            Min = min(Observations),\n            Max = max(Observations),\n            Range = Max - Min) |&gt; \n  ungroup()\n\n#print the table\ncond_form_tables(summary_table)\n\n\n\n\nLocationSpeciesMeanMedianMinMaxRange\n\nLocation ASpecies 112.8 139178\n\nLocation ASpecies 211   1102222\n\nLocation ASpecies 37.82821210\n\nLocation BSpecies 115.1 1542622\n\nLocation BSpecies 217   1713207\n\nLocation BSpecies 311.9 1261711\n\nLocation CSpecies 16.11601818\n\nLocation CSpecies 23.033077\n\nLocation CSpecies 38.0885116\n\nLocation DSpecies 19.84107136\n\nLocation DSpecies 28.09801919\n\nLocation DSpecies 34.94501212\n\n\n\n\nCool, and for fun, lets also say that we are interested to know how many times the observation count of the species was above 10 at each site:\n\n\nCode\n#number of observations above n\nsummary_table_2 &lt;- fish_obs_df |&gt; \n  filter(Observations &gt; 10) |&gt; \n  group_by(Location, Species) |&gt; \n  summarise(CountAbove10 = n()) |&gt; \n  ungroup()\n\n#add the count to the main table\nsummary_table &lt;- left_join(summary_table, summary_table_2)\n\n#print the table\ncond_form_tables(summary_table)\n\n\n\n\nLocationSpeciesMeanMedianMinMaxRangeCountAbove10\n\nLocation ASpecies 112.8 139178238\n\nLocation ASpecies 211   1102222136\n\nLocation ASpecies 37.8282121020\n\nLocation BSpecies 115.1 1542622225\n\nLocation BSpecies 217   1713207256\n\nLocation BSpecies 311.9 1261711192\n\nLocation CSpecies 16.1160181834\n\nLocation CSpecies 23.033077\n\nLocation CSpecies 38.08851163\n\nLocation DSpecies 19.8410713669\n\nLocation DSpecies 28.0980191973\n\nLocation DSpecies 34.945012121\n\n\n\n\nNow, for the purposes of this learning experience, lets say that this initial analysis above is something that I will need to do every time I load a dataset, and is therefore a perfect time to write a function to do the analysis for me. So do I go from the code I have written to a function? Like this:\n\nIdentify the code to go in the function (we’ve done this).\nPut the code inside the function wrapper my_custom_function &lt;- function(input){right here!}:\n\n\n\nCode\nmy_custom_function &lt;- function(inputs){\n  \n  #generic summary stats\n  summary_table &lt;- fish_obs_df |&gt; \n    group_by(Location, Species) |&gt; \n    summarise(Mean = round(mean(Observations),2),\n              Median = median(Observations),\n              Min = min(Observations),\n              Max = max(Observations),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- fish_obs_df |&gt; \n    filter(Observations &gt; 10) |&gt; \n    group_by(Location, Species) |&gt; \n    summarise(CountAbove10 = n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n\n}\n\n\n\nIdentify the inputs required for the code to run:\n\n\n\nCode\nmy_custom_function &lt;- function(inputs){\n  \n  #generic summary stats\n  summary_table &lt;- fish_obs_df |&gt; #the fish_obs_df dataset is an input, we need to tell the function what dataset to use\n    group_by(Location, Species) |&gt; #the Location and Species columns are inputs, we need to tell the function what columns to group by\n    summarise(Mean = round(mean(Observations),2), #the Observation column is an input, we need to tell the function what columns calculate on\n              Median = median(Observations),\n              Min = min(Observations),\n              Max = max(Observations),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- fish_obs_df |&gt; \n    filter(Observations &gt; 10) |&gt; #the value 10 is an input, we need to tell the function what cut off value to use\n    group_by(Location, Species) |&gt; \n    summarise(CountAbove10 = n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n\n}\n\n\n\nLooks like we have five different inputs, next we give each of those inputs their own placeholder:\n\n\n\nCode\nmy_custom_function &lt;- function(x,y,z,a,b){\n  \n  #generic summary stats\n  summary_table &lt;- x |&gt; #the fish_obs_df dataset is now \"x\"\n    group_by({{y}}, {{z}}) |&gt; #the Location and Species columns are now \"y\" and \"z\" we need to use curly-curly brackets for column names provided externally\n    summarise(Mean = round(mean({{a}}),2), #the Observation column is now \"a\"\n              Median = median({{a}}),\n              Min = min({{a}}),\n              Max = max({{a}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- x |&gt; \n    filter({{a}} &gt; {{b}}) |&gt; #the value is now \"b\"\n    group_by({{y}}, {{z}}) |&gt; \n    summarise(CountAbove10 = n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n\n}\n\n\n\nSpecify the output of the function:\n\n\n\nCode\nmy_custom_function &lt;- function(x,y,z,a,b){\n  \n  #generic summary stats\n  summary_table &lt;- x |&gt; \n    group_by({{y}}, {{z}}) |&gt; \n    summarise(Mean = round(mean({{a}}),2), \n              Median = median({{a}}),\n              Min = min({{a}}),\n              Max = max({{a}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- x |&gt; \n    filter({{a}} &gt; {{b}}) |&gt; \n    group_by({{y}}, {{z}}) |&gt; \n    summarise(CountAbove10 = n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n\n  #what should be returned?\n  return(summary_table)\n\n}\n\n\n\nRun the function:\n\n\n\nCode\nmy_custom_function &lt;- function(x,y,z,a,b){\n  \n  #generic summary stats\n  summary_table &lt;- x |&gt; \n    group_by({{y}}, {{z}}) |&gt; \n    summarise(Mean = round(mean({{a}}),2), \n              Median = median({{a}}),\n              Min = min({{a}}),\n              Max = max({{a}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- x |&gt; \n    filter({{a}} &gt; {{b}}) |&gt; #the value is now \"b\"\n    group_by({{y}}, {{z}}) |&gt; \n    summarise(CountAbove10 = n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n  \n  #what should be returned?\n  return(summary_table)\n\n}\n\n\nnow, if we run the code, the function will appear in your global environment on the right. Congratulations, you just made a function. Lets see if it works:\n\n\nCode\n#run the function\nmy_custom_function(x = fish_obs_df,\n                   y = Location,\n                   z = Species,\n                   a = Observations,\n                   b = 10) \n\n\n\n\nLocationSpeciesMeanMedianMinMaxRangeCountAbove10\n\nLocation ASpecies 112.8 139178238\n\nLocation ASpecies 211   1102222136\n\nLocation ASpecies 37.8282121020\n\nLocation BSpecies 115.1 1542622225\n\nLocation BSpecies 217   1713207256\n\nLocation BSpecies 311.9 1261711192\n\nLocation CSpecies 16.1160181834\n\nLocation CSpecies 23.033077\n\nLocation CSpecies 38.08851163\n\nLocation DSpecies 19.8410713669\n\nLocation DSpecies 28.0980191973\n\nLocation DSpecies 34.945012121\n\n\n\n\nToo Easy!\nOk, spoiler, we are not actually done yet. First of all, lets make those place holders more helpful:\n\n\nCode\nmy_custom_function &lt;- function(df, group_col_1, group_col_2, value, cut_off_value){\n  \n  #generic summary stats\n  summary_table &lt;- df |&gt; \n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(Mean = round(mean({{value}}),2), \n              Median = median({{value}}),\n              Min = min({{value}}),\n              Max = max({{value}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- df |&gt; \n    filter({{value}} &gt; {{cut_off_value}}) |&gt;\n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(CountAbove10 = n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n  \n  #what should be returned?\n  return(summary_table)\n\n}\n\n\nSecondly, lets make the column name for the cut off value adaptive to the actual cut off value:\n\n\nCode\nmy_custom_function &lt;- function(df, group_col_1, group_col_2, value, cut_off_value){\n  \n  #generic summary stats\n  summary_table &lt;- df |&gt; \n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(Mean = round(mean({{value}}),2), \n              Median = median({{value}}),\n              Min = min({{value}}),\n              Max = max({{value}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- df |&gt; \n    filter({{value}} &gt; {{cut_off_value}}) |&gt; \n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(!!sym(glue(\"CountAbove{cut_off_value}\")) := n()) |&gt; #we have to use !!sym() when the name is not named col. We also use \":=\" in place of the normal equals\n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n  \n  #what should be returned?\n  return(summary_table)\n\n}\n\n\nThird, lets identify what kind of dependencies this function has, i.e., what kind of functions does it rely on and what packages would we have to load for it to work:\n\n\nCode\nmy_custom_function &lt;- function(df, group_col_1, group_col_2, value, cut_off_value){\n  \n  #load the required packages\n  library(dplyr)\n  library(glue)\n  \n  #generic summary stats\n  summary_table &lt;- df |&gt; \n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(Mean = round(mean({{value}}),2), \n              Median = median({{value}}),\n              Min = min({{value}}),\n              Max = max({{value}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- df |&gt; \n    filter({{value}} &gt; {{cut_off_value}}) |&gt; #the value is now \"b\"\n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(!!sym(glue(\"CountAbove{cut_off_value}\")) := n()) |&gt; \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n  \n  #what should be returned?\n  return(summary_table)\n\n}\n\n\nForth, what if the packages haven’t been installed? Lets add a check and warning for this:\n\n\nCode\nmy_custom_function &lt;- function(df, group_col_1, group_col_2, value, cut_off_value){\n  \n  #set a vector of names of packages we need\n  pkg &lt;- c(\"dplyr\", \"glue\")\n  \n  # Loop through each package\n  for (p in pkg) {\n    if (!requireNamespace(p, quietly = TRUE)) {\n      warning(sprintf(\"The package '%s' is not installed. Please install it with install.packages('%s')\", p, p))\n    } else {\n      library(p, character.only = TRUE)\n    }\n  }\n  \n  #generic summary stats\n  summary_table &lt;- df |&gt; \n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(Mean = round(mean({{value}}),2), \n              Median = median({{value}}),\n              Min = min({{value}}),\n              Max = max({{value}}),\n              Range = Max - Min) |&gt; \n    ungroup()\n\n  #number of observations above n\n  summary_table_2 &lt;- df |&gt; \n    filter({{value}} &gt; {{cut_off_value}}) |&gt; #the value is now \"b\"\n    group_by({{group_col_1}}, {{group_col_2}}) |&gt; \n    summarise(!!sym(glue(\"CountAbove{cut_off_value}\")) := n()) |&gt;  \n    ungroup()\n  \n  #add the count to the main table\n  summary_table &lt;- left_join(summary_table, summary_table_2)\n  \n  #what should be returned?\n  return(summary_table)\n\n}\n\n\nNow this is starting to look like a real function! Lets do some testing to make sure those adjustments worked fine:\n\n\nCode\ncut_off_is_10 &lt;- my_custom_function(df = fish_obs_df,\n                                    group_col_1 = Location,\n                                    group_col_2 = Species,\n                                    value = Observations,\n                                    cut_off_value = 10)\n\ncond_form_tables(cut_off_is_10)\n\n\n\n\nLocationSpeciesMeanMedianMinMaxRangeCountAbove10\n\nLocation ASpecies 112.8 139178238\n\nLocation ASpecies 211   1102222136\n\nLocation ASpecies 37.8282121020\n\nLocation BSpecies 115.1 1542622225\n\nLocation BSpecies 217   1713207256\n\nLocation BSpecies 311.9 1261711192\n\nLocation CSpecies 16.1160181834\n\nLocation CSpecies 23.033077\n\nLocation CSpecies 38.08851163\n\nLocation DSpecies 19.8410713669\n\nLocation DSpecies 28.0980191973\n\nLocation DSpecies 34.945012121\n\n\n\n\n\n\nCode\ncut_off_is_20 &lt;- my_custom_function(df = fish_obs_df,\n                                    group_col_1 = Location,\n                                    group_col_2 = Species,\n                                    value = Observations,\n                                    cut_off_value = 20) \n\ncond_form_tables(cut_off_is_20)\n\n\n\n\nLocationSpeciesMeanMedianMinMaxRangeCountAbove20\n\nLocation ASpecies 112.8 139178\n\nLocation ASpecies 211   11022221\n\nLocation ASpecies 37.82821210\n\nLocation BSpecies 115.1 154262219\n\nLocation BSpecies 217   1713207\n\nLocation BSpecies 311.9 1261711\n\nLocation CSpecies 16.11601818\n\nLocation CSpecies 23.033077\n\nLocation CSpecies 38.0885116\n\nLocation DSpecies 19.84107136\n\nLocation DSpecies 28.09801919\n\nLocation DSpecies 34.94501212\n\n\n\n\nLooking good to me. What we have now is our very own custom function that:\n\ntakes a dataframe, two grouping columns, a value column, and a cut-off/objective value\nand returns a summary dataframe as well as the number of observations that were above the cut-off\n\nHowever, there is still one glaring gap that I find alot of tutorials skip over… this code is still in the same script! All we have really done is make it longer and slightly abstracted so far!\nThe final stage of creating our custom function is saving and tucking away the function somewhere else so we can then refer to it later as we need. Doing this is not to hard:\n\nOpen a new R script. Not a .qmd file, or a markdown file, a pure R script.\nCopy and paste the custom function into the new R script.\nSave this script somewhere relevant, I like to create a folder in my work space called “functions”.\n\nDone. To access the function that we just put inside the script we then write the following code:\n\n\nCode\nsource(\"path_to_script/script_name.R\")\n\n\nThis will load the function into your global environment ready for use."
  },
  {
    "objectID": "posts/going_loopy_for_for_loops/index.html",
    "href": "posts/going_loopy_for_for_loops/index.html",
    "title": "Going Loopy for For Loops",
    "section": "",
    "text": "Here’s the scene, you’ve started on your R coding journey, know how to create an object, how to discern between vectors and lists, maybe even written a few short scripts. Then all of a sudden your professor/teacher/boss pulls a fast one on you and introduces for loops. For loops? What are they? How’s that work? Whats going on? You struggle through and complete the task, but didn’t quite understand what was going on when they explained it to you… Well at least that’s how it went for me.\nIn this post I wanted to quickly talk about for loops in R, specifically, I’m looking to cover:\n\nWhat is really happening in a for loop\nWhere you can go to read about for loops in much (much) more detail\nWhy you might want to write a for loop\nHow you can start to write your own loops\nAnd ironically, why I actually try to avoid using for loops"
  },
  {
    "objectID": "posts/going_loopy_for_for_loops/index.html#i-the-iteration",
    "href": "posts/going_loopy_for_for_loops/index.html#i-the-iteration",
    "title": "Going Loopy for For Loops",
    "section": "2.1 i The Iteration",
    "text": "2.1 i The Iteration\n“i” can be anything, which is not super helpful (sorry). What might be helpful is just seeing an example. This code:\n\n\nCode\n#write a for loop to print the numbers 1 to 10\nfor (PotatoSalad in 1:10){\n  print(PotatoSalad)\n}\n\n\nwill produce the exact same result as this code:\n\n\nCode\n#write a for loop to print the numbers 1 to 10\nfor (i in 1:10){\n  print(i)\n}\n\n\nWe use “i” as an iteration counter (hence usually getting called “i”) that keeps track of what loop we are on with respect to n. For our example above, n is 10. So on the first loop “i” is 1, on the second loop “i” is 2, on the third loop “i” is three…, all the way until “i” is 10. At that point, the for loop finishes. Hopefully it is now intuitive to see how print(i) produces the numbers it does."
  },
  {
    "objectID": "posts/going_loopy_for_for_loops/index.html#n-the-range",
    "href": "posts/going_loopy_for_for_loops/index.html#n-the-range",
    "title": "Going Loopy for For Loops",
    "section": "2.2 n The Range",
    "text": "2.2 n The Range\n“n” is the range of the loop. “n” tells the for loop two things;\n\nHow many times to continue looping\nWhat elements to loop over\n\nIn our example above, n is 10. But wait, that’s not quite right, n is actually 1 to 10. This is an important distinction to make because it is usually one of the first places we make errors. Lets take a look:\n\n\nCode\n#write a for loop to print the number 10 (spot the issue)\nfor (i in 10){\n  print(i)\n}\n\n\n[1] 10\n\n\nAs you can see, when “n” is just 10, then the output is only the value “10”. This is because the range (AKA length) of “n” was only 1. An easy way to check this is to use the length() function:\n\n\nCode\nlength(10)\n\n\n[1] 1\n\n\n\n\nCode\nlength(1:10)\n\n\n[1] 10\n\n\nSo the first super important thing to remember is that “n” is a range, it has a point you want to start at, and a point you want to end at. The second super important thing to remember about “n” is that it directly tells the specific value to start and end at, and therefore determine the value that “i” is going to be. Here is a simple demonstration:\n\n\nCode\n#write a for loop to print the numbers 15 to 22\nfor (i in 15:22){\n  print(i)\n}\n\n\n[1] 15\n[1] 16\n[1] 17\n[1] 18\n[1] 19\n[1] 20\n[1] 21\n[1] 22\n\n\nIn this case, we started at 15 and ended at 22. So on the first loop, “i” is 15, second loop “i” is 16, etc.\nThe last super important thing to remember about “n” does not have to be numeric! It look me a while to realize this, but it can allow you to do some cool things. Here is another quick example:\n\n\nCode\n#create a vector of character elements\nn_range &lt;- c(\"PotatoSalad\", \"FishFingers\", \"Im... Kinda Hungry\")\n\n#write a for loop to print this vector one element at a time\nfor (i in n_range){\n  print(i)\n}\n\n\n[1] \"PotatoSalad\"\n[1] \"FishFingers\"\n[1] \"Im... Kinda Hungry\"\n\n\nThis does through a minor curve ball though. Did you notice that the code is now for (i in n_range), there is no “1:” in front of “n_range”, this is just because the object “n_range” already has a range of elements that we can loop over. Lets use length() again to show this:\n\n\nCode\nlength(n_range)\n\n\n[1] 3\n\n\nIf you can remember these core things about for loops you will get very, very far with them. So to summarise. “n”:\n\nMust be a range, it needs a start and end point\nTells “i” what value it is going to be\nCan be a numeric, or character!"
  },
  {
    "objectID": "posts/going_loopy_for_for_loops/index.html#f-the-function",
    "href": "posts/going_loopy_for_for_loops/index.html#f-the-function",
    "title": "Going Loopy for For Loops",
    "section": "2.3 f The Function",
    "text": "2.3 f The Function\nThe final part of a for loop is by far the biggest part of the code, but it is ironically very straight forward to understand if you have a little bit of an R background. The function or functions inside a for loop are the exact same functions that you would be using outside a for loop! The hard part to figure out is where to place that stupid “i” value. Personally, I haven’t been able to find a method of explaining where “i” goes other than by being very conscious of the purpose of your for loop. Start with simple and short loops and work your way to more complicated tasked, it will come naturally. Generally you will find that “i” only needs to be placed in a few key locations, however if you miss a spot, happy debugging!\n\n\n\n\n\n\nNote\n\n\n\nWant to learn more about For Loops from the professionals? Check out the Iteration chapter in R for Data Science!"
  },
  {
    "objectID": "posts/going_loopy_for_for_loops/index.html#the-scenario",
    "href": "posts/going_loopy_for_for_loops/index.html#the-scenario",
    "title": "Going Loopy for For Loops",
    "section": "3.1 The Scenario",
    "text": "3.1 The Scenario\nSomething I do almost every day is make maps. Usually fairly simple maps, often they show sample site locations, or coral monitoring locations, or the size of a seagrass meadow, things like that. These maps are included in static word documents and are often needed over large chunks of areas. However, the combination of a large study location, a high quantity of sample site locations, and a static output (can’t put an interactive map into word), means that instead of one large map, I need to create lots of small maps for each little area.\nThis here, is an absolutely prime example of a compelling reason to use a for loop. To give you some numbers, in one my projects I need to create 67 maps. If I was to manually write out the code for each of those 67 maps, my script would have 3886 lines of code just dedicated to creating the maps. Instead, I use a for loop and pull 67 maps out of less than 100 lines of code. Not only that, but I also reduce the chance of an error sneaking into my code by 67x.\nBelow is a simplified mock up of the code I would use for this, noting that I have used made up sampling locations for data privacy, and created interactive maps for your enjoyment. We will see the full code in action first, then break it down step by step.\n\n\nCode\n#read in some example data that I made up\nexample_sites &lt;- st_read(\"example_data.gpkg\")\n\n#extract an object that contains the three unique locations we are looking at\nlocations &lt;- unique(example_sites$Location)\n\n#create a list that will store my maps\nlist_of_maps &lt;- setNames(vector(\"list\", length(locations)), locations)\n\n#initialize the for loop\nfor (i in locations){\n  \n  #filter our dataset\n  sub_set_of_sites &lt;- example_sites |&gt; \n    filter(Location == i)\n  \n  #create a simple map\n  single_map &lt;- tm_shape(sub_set_of_sites) +\n    tm_dots(shape = \"Site\", size = 1, col = \"Site\", fill = \"Site\") +\n    tm_text(\"Site\", size = 2, ymod = 1) +\n    tm_layout(legend.show = F)\n  \n  #add each map to the list\n  list_of_maps[[i]] &lt;- single_map\n  \n}\n\n\nHere is how one of the maps looks:\n\n\nCode\n#view the map\nlist_of_maps[[\"Alligator Creek\"]]"
  },
  {
    "objectID": "posts/going_loopy_for_for_loops/index.html#the-breakdown",
    "href": "posts/going_loopy_for_for_loops/index.html#the-breakdown",
    "title": "Going Loopy for For Loops",
    "section": "3.2 The Breakdown",
    "text": "3.2 The Breakdown\nTime to take a closer look at whats happening here.\n\nFirst of all, i use a function called st_read() from the sf package to load in my dataset. For the purposes of this post, we don’t need to worry about this package and its functions. Check out my other posts for more details on this area. What I will do here though, is show a sneak peak of the data.\n\n\n\nCode\n#read in some example data that I made up\nexample_sites &lt;- st_read(\"example_data.gpkg\")\n\n\n\n\n\n\nLocationSiteXY\n\nAlligator CreekSite 1147-19.3\n\nAlligator CreekSite 2147-19.3\n\nAlligator CreekSite 3147-19.3\n\nThe StrandSite 1147-19.2\n\nTown CommonSite 1147-19.2\n\nTown CommonSite 2147-19.2\n\nTown CommonSite 3147-19.2\n\nMagnetic IslandSite 1147-19.2\n\nMagnetic IslandSite 2147-19.2\n\n\n\n\n\nFrom this dataset I then extract a vector of unique locations, which in this case we can easily see is just the four (Alligator Creek, The Strand, Town Common, Magnetic Island).\n\n\n\nCode\n#extract an object that contains the three unique locations we are looking at\nlocations &lt;- unique(example_sites$Location)\n\n\n\nI then create a list to store the outputs of my for loop. This step can be done a wide range of ways, for example you could store each output as a separate object, if you know the number of outputs you could pre-define a list of that length to store the outputs (like I did), or if the number of outputs is a mystery you can grow the list as you go. There is no “best” way to do this, however it is generally frowned upon to grow the list as you go, as this can be computationally quite expensive. My recommendation would be to use the first two options, favoring a list with a pre-defined length if you can.\n\n\n\nCode\n#create a list that will store my maps\nlist_of_maps &lt;- setNames(vector(\"list\", length(locations)), locations)\n\n\n\nThe set up is done and it is now time to begin the for loop. This section of the code is a good time to review what we discussed above. We can see that I am going to loop over “locations”, and for each loop “i” will become of the elements in “locations”.\n\n\n\nCode\n#initialize the for loop\nfor (i in locations){\n\n\n\nWe are now working within the for loop. Remember, this section of the code will be run again and again and again. The first thing we do inside the for loop is take a subset of our data. We can filter the data by “i” because “i” has taken on the first element of “location”.\n\n\n\nCode\n  #filter our dataset\n  sub_set_of_sites &lt;- example_sites |&gt; \n    filter(Location == i)\n\n\n\nUsing the subset of the data, which will now only contains rows from one location thanks to our filter. We then create the map. I like to use the tmap package, however there is a wide range of options available. Maybe I will write a post on mapping with tmap one day… we will see.\n\n\n\nCode\n  #create a simple map\n  single_map &lt;- tm_shape(sub_set_of_sites) +\n    tm_dots(shape = \"Site\", size = 1, col = \"Site\", fill = \"Site\") +\n    tm_text(\"Site\", size = 2, ymod = 1) +\n    tm_layout(legend.show = F)\n\n\n\nThe final step of our for loop is to save the output of the loop somewhere. This step can catch alot of people off guard, they write the perfect loop, they check everything runs properly, and then they forgot to save the output each loop. Shame.\n\nIn my case, I have put the map into the list that we defined earlier. Notice that because I named each item in the list, I can then place the map under the correct item using “i”.\n\n\nCode\n  #add each map to the list\n  list_of_maps[[i]] &lt;- single_map\n  \n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, Im Adam.",
    "section": "",
    "text": "Document\n\n\n\n  \n    \n      Hi, Im Adam.\n      An environmental data analyst decoding nature's secrets.\n      \n      \n       With experience in R, Tableau, SQL and GIS, I transform raw environmental data into meaningful narratives with stunning visuals. From crafting data-driven solutions to fostering sustainability, I am dedicated to bridging the gap between technology and the environment."
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "ADAM SHAND",
    "section": "",
    "text": "Document\n\n\n\n  \n    \n      \n    \n      Download Current CV"
  },
  {
    "objectID": "posts/an_opinionated_dataframe_cleaner/index.html",
    "href": "posts/an_opinionated_dataframe_cleaner/index.html",
    "title": "An Opinionated Dataframe Cleaner",
    "section": "",
    "text": "1 Introduction\nInconsistent and illogical naming conventions can ruin even the best analysts flow, cause sneaky errors, and potentially lead to misleading or completely incorrect results. Throughout my time as an environmental data analyst I have come across countless instances where the names used in a dataframe mess up my analysis, and I can guarantee I’m not the only one. Just Google “the importance of file naming” to find countless monologues (just like this one), or “bad naming conventions” to realize, actually it could be worse!\nSo if this is such a widely acknowledged issue, why is it still an issue? How has it not been fixed? Simply put, because a) its boring, and b) everyone is unique and has their own idea of what a “good” system looks like. This leads to people not bothering, or instances where you might pull together several datasets from a range of sources, each using their own (different) naming conventions. Thankfully, if each dataset is at least internally consistent, we can address these differences.\nBelow, I introduce my method of addressing this issue. It is a highly opinionated dataframe cleaner that focuses exclusively on ensuring every dataframe I touch receives exactly the same column naming convention. Before we dive into it, I believe it is critical to recognise that this method is customized to my needs, it may work for you as well, but I recommend instead that you use this as inspiration to develop your own method.\n\n\n2 The Naming Convention\nSo what naming convention am I using exactly? “Upper Camel Case” is my choice, however some people may also refer to it as “Pascal Case”. If your are unfamiliar, here are some examples of naming conventions:\n\nUpperCamelCase\nsnake_case\nkebab-case\nUPPERFLATCASE\netc.\n\nWhy UpperCamelCase? As noted above, everyone has their own idea of what is good. I find that upper camel case suite my purposes well, it is fairly easy to read, it only contains A-Z, 0-9 (no underscores or dashes), and most importantly it does not clash with my object names when coding it in R. What I mean by this is that I use snake_case to name my objects, and UpperCamelCase to name columns within my objects. Lets consider the following example.\nLets say I have a dataframe that counts fish (called “fish”):\n\n\nCode\n#load the dplyr package\nlibrary(dplyr)\n\n#create an example dataframe\nfish &lt;- data.frame(species = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                   fish_count_location_1 = c(6,9,3,5,10),\n                   fish_count_location_2 = c(1,16,3,2,7))\n\n#print the dataframe. If you want to learn about this function, check out my pretty tables post!\ncond_form_tables(fish)\n\n\n\n\nspeciesfish_count_location_1fish_count_location_2\n\nA61\n\nB916\n\nC33\n\nD52\n\nE107\n\n\n\n\n(Note that both the object and column names are in snake_case).\nThen I decide to figure out the mean number of each species of fish, across all locations (called “mean_fish”):\n\n\nCode\n#get the rowwise mean of the fish counts per species\nmean_fish &lt;- fish |&gt; \n  rowwise() |&gt; \n  mutate(mean_fish = mean(c(fish_count_location_1, fish_count_location_2))) |&gt; \n  ungroup()\n\n#print the dataframe\ncond_form_tables(mean_fish)\n\n\n\n\nspeciesfish_count_location_1fish_count_location_2mean_fish\n\nA613.5\n\nB91612.5\n\nC333  \n\nD523.5\n\nE1078.5\n\n\n\n\nWhoops, just by using some logical naming I now accidentally have a dataframe object named “mean_fish”, and a column within that dataframe named “mean_fish”. Now obviously this is a silly example, but imaging we have 1000+ lines of code, and we need to know something about the mean number of fish. Suddenly we can’t remember whats an object and whats a column and we can run into subtle errors, or have very confusing lines of codes.\nThus; my final reason for choosing UpperCamelCase:\n\n\nCode\n#create a new example dataframe\nfish &lt;- data.frame(Species = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                   FishCountLocation1 = c(6,9,3,5,10),\n                   FishCountLocation2 = c(1,16,3,2,7))\n\n#get the rowwise mean of the fish counts per species\nmean_fish &lt;- fish |&gt; \n  rowwise() |&gt; \n  mutate(mean_fish = mean(c(FishCountLocation1, FishCountLocation2))) |&gt; \n  ungroup()\n\n#print the dataframe\ncond_form_tables(mean_fish)\n\n\n\n\nSpeciesFishCountLocation1FishCountLocation2mean_fish\n\nA613.5\n\nB91612.5\n\nC333  \n\nD523.5\n\nE1078.5\n\n\n\n\n\n\n3 The Function\nMy custom function takes advantage of the janitor R package, which includes a wide range of functions to perform standard cleaning and organisation steps (check out the janitor documentation to see what it can do). Specifically, we are going to use the clean_names() function, along with some bells and whistles to catch our edge cases. Lets take a look:\n\n\nCode\n#create the custom function\nname_cleaning &lt;- function(df){\n\n  #load and install (if required) the pacman package handler package, which we will use for all future package downloads\n  if(!require(\"pacman\")){install.packages(\"pacman\")}\n\n  #use the pacman function to load and install (if required) all other packages\n  pacman::p_load(janitor, dplyr, sf, stringr)\n\n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n    \n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n    \n    #bind the geometry column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = st_geometry(df)) |&gt; \n      st_as_sf()\n  \n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n  \n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n  \n  return(df_new)\n  \n}\n\n\nOk, so even though that is a relatively short function, there is still a few things going on. Lets break it down a bit.\n\nFirst we will initialize the function (if you are unfamiliar with creating your own functions check out my functions post).\n\n\n\nCode\n#initialize the function\nname_cleaning &lt;- function(df){\n\n\n\nThen we load each of our required packages. Noting that generally we would expect these packages to already have been loaded in by the script calling this function, but we can’t be sure. Here we use the pacman package to make the install/load steps a bit more streamline, documentation for pacman can be found here.\n\n\n\nCode\n  #load and install (if required) the pacman package handler package, which we will use for all future package downloads\n  if(!require(\"pacman\")){install.packages(\"pacman\")}\n\n  #use the pacman function to load and install (if required) all other packages\n  pacman::p_load(janitor, dplyr, sf, stringr)\n\n\n\nWe then check if the dataframe we are cleaning is actually an “sf” (simple feature) object. Sf objects are special types of dataframes used in geospatial analytics that have an extra column containing coordinate information. This special column has its own rules for column naming and therefore sf objects should be handled differently. In my work I encounter sf objects very often.\n\n\n\nCode\n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n\n\n\nIf we are looking at an sf object, we copy the sf object and remove the geometry column from this copy. Following this, we can then run janitor’s clean_names() function on the copy with no geometry column. The reason we do this is that the janitor package has no precedent for sf objects. In the clean_names() function, we specify that we want the column names to follow the “upper_camel” format. This will convert all our column names to the desired format.\n\n\n\nCode\n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n\n\n\nOnce we have cleaned the names of every column in the sf object, we can then add the special geometry column back on to the dataset. At this point we also need to convert the object back to the “sf” type.\n\n\n\n\n\n\n\nNote\n\n\n\nYou may notice that this special geometry column is called “geom” rather than “Geom”… which doesn’t adhere to our naming convention. Unfortunately, this is an annoying quirk of spatial datasets. When they are loaded, the geometry column can take on 1 of 3 different names depending on the source of the data; “geom”, “geometry”, or “shape”. In all cases the name is lowercase, even when the data is saved in uppercase, it will be reloaded in lowercase. Thus, for this issue, we simply ensure that the 3 different possibilities are all just converted to the “geom” option.\n\n\n\n\nCode\n    #bind the geometry column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = st_geometry(df)) |&gt; \n      st_as_sf()\n\n\n\nIf the object is a simple dataframe (not an sf object), we can just move straight to the clean_names() step that we explained above.\n\n\n\nCode\n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n\n\n\nNext we look to catch strange edge cases related to the encoding column of columns. You are likely familiar with the concept of a column being of type “character” or “numeric” or “boolean”, etc. Our strange edge case is similar to this. What we have found is that in some instances the character column type is encoded as “UTF-8”, while other times it is encoded as “ASCII”. Much like how you can’t combine character and numeric columns, you also can’t combine columns encoded as UTF-8 and ASCII. Below we convert all columns encoded as UTF-8 to ASCII to avoid this issue.\n\n\n\n\n\n\n\nNote\n\n\n\nPlease note that these encodings are hidden from the user and you will never normally need to interact with them, the reason this happens doesn’t matter, and is frankly some mysterious property of excel. Broadly, you probably don’t need to ever understand why/how this step works.\n\n\n\n\nCode\n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n\n\n\nThe object is then returned and the function is complete.\n\n\n\nCode\n  return(df_new)\n  \n}\n\n\n\n\n4 In Practice\nNow that we understand how the function works, lets demonstrate its use with another example dataset that has a wide range of column names. Here is before:\n\n\nCode\n#create an example table with example names\nexample_df &lt;- data.frame(\"column 1\" = c(1,2,3,4,5),\n                         \"column-2\" = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                         \"column_3\" = c(NA, NA, NA, NA, NA),\n                         \"column-four\" = c(\"1A\", \"2B\", \"3C\", \"4D\", \"5E\"),\n                         \"Column Five\" = c(TRUE, FALSE, TRUE, FALSE, TRUE))\n\n#print the table\nprint(example_df)\n\n\n  column.1 column.2 column_3 column.four Column.Five\n1        1        A       NA          1A        TRUE\n2        2        B       NA          2B       FALSE\n3        3        C       NA          3C        TRUE\n4        4        D       NA          4D       FALSE\n5        5        E       NA          5E        TRUE\n\n\nAnd after:\n\n\nCode\n#run the clean name functions\nexample_df_cleaned &lt;- name_cleaning(example_df)\n\n#print the cleaned dataset\ncond_form_tables(example_df_cleaned)\n\n\n\n\nColumn1Column2Column3ColumnFourColumnFive\n\n1A1ATRUE\n\n2B2BFALSE\n\n3C3CTRUE\n\n4D4DFALSE\n\n5E5ETRUE\n\n\n\n\n\n\n5 Caveats\nIt is also important to acknowledge the caveats of your own work. To my knowledge the only caveat of this function is that it relies on a sensible preexisting column name, even if the format is horrible. What I mean by this is that a column named “Mean-fish_in Townsville” can be cleaned, but a column with no name… well how can you rename that to something appropriate? As a side note R does generally replace empty column names with “X1”, “X2”, etc. however this still does not provide any information about the column."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Environmental Bytes for a Better Earth",
    "section": "",
    "text": "Document\n\n\n  \n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nAn Opinionated Dataframe Cleaner\n\n\n\n\n\nNaming your dataframe columns doesn’t have to be hard, does it? Here I demonstrate the benefits of implimenting an opionated dataframe cleaner to help keep your columns organised.\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGoing Loopy for For Loops\n\n\n\n\n\nWhats the point of for loops? Well for looping of course. In this post I break down how to write for loops in R, how you can easily understand them, and compelling reasons that you might want to learn them yourself!\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLearning To Create Your Own Custom Functions\n\n\n\n\n\nHaving the ability to create functions is both a blessing and a curse. You are gifted with limitless potential, but absolutely limited power supply (AKA your brain). In this post I discuss how I learnt to make my own functions and the trials I faced along the way.\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAn Epic Battle Between For Loops and Vectorised Functions\n\n\n\n\n\nTBD.\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating to Version 4 of the tmap R Package\n\n\n\n\n\nMy favourite mapping package just released a major update! In this post I discuss the changes made as they relate to my work, and provide some tips and tricks I have learnt so far when migration from Version 3.0 to Version 4.0.\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/loops_and_vectorised_functions/index.html",
    "href": "posts/loops_and_vectorised_functions/index.html",
    "title": "An Epic Battle Between For Loops and Vectorised Functions",
    "section": "",
    "text": "This is going to be a different kind of blog. Less about teaching, and more about the explorative process as I try to understand myself the differences between loops and vectorised functions.\nMain points to hit\n\nkey: this is the natural follow up from writing your own function AND from creating for loops\nthe comparison between for loops and vectorised functions, why should you try to move over to vectorised functions\n\nimproved run time (usually)\nhuman time (more important) - although sometimes I doubt readability\n\nhow did I learn to understand vectorised functions\nwhat is a compelling reason to try/learn"
  }
]