[
  {
    "objectID": "projects/out_of_the_shadows/index.html",
    "href": "projects/out_of_the_shadows/index.html",
    "title": "Using Artificial Intelligence for Automatic Fish Detection from Acoustic Cameras",
    "section": "",
    "text": "Tip\n\n\n\n Out of the shadows: automatic fish detection from acoustic cameras:  Efficacious monitoring of fish stocks is critical for efficient management. Multibeam acoustic cameras, that use sound-reflectance to generate moving pictures, provide an important alternative to traditional video-based methods that are inoperable in turbid waters. However, acoustic cameras, like standard video monitoring methods, produce large volumes of imagery from which it is time consuming and costly to extract data manually. Deep learning, a form of machine learning, can be used to automate the processing and analysis of acoustic data. We used convolutional neural networks (CNNs) to detect and count fish in a publicly available dual-frequency identification sonar (DIDSON) dataset. We compared three types of detections, direct acoustic, acoustic shadows, and a combination of direct and shadows. The deep learning model was highly reliable at detecting fish to obtain abundance data using acoustic data. Model accuracy for counts-per-image was improved by the inclusion of shadows (F1 scores, a measure of the model accuracy: direct 0.79, shadow 0.88, combined 0.90). Model accuracy for MaxN per video was high for all three types of detections (F1 scores: direct 0.90, shadow 0.90, combined 0.91). Our results demonstrate that CNNs are a powerful tool for automating underwater acoustic data analysis. Given this promise, we suggest broadening the scope of testing to include a wider range of fish shapes, sizes, and abundances, with a view to automating species (or ‘morphospecies’) identification and counts."
  },
  {
    "objectID": "projects/conquering_reports_with_r/index.html",
    "href": "projects/conquering_reports_with_r/index.html",
    "title": "Conquering Environmental Reporting Using R",
    "section": "",
    "text": "Tip\n\n\n\n Work-In-Progress, no current link. \nThis is currently a work in progress stored on a private repository on GitHub. The project has been written for the Dry Tropics Partnership for Healthy Waters, and can be considered my most important body of work thus far. Below is a schematic overview of the repository."
  },
  {
    "objectID": "photography/index.html",
    "href": "photography/index.html",
    "title": "Photography",
    "section": "",
    "text": "Rules for adding images:\n\nImage ratio must be 16:9.\nImage quality should be at least 1600 x 900 (note the lack of quality in lightbox).\nImages must be added in sets of 4 for the images to appear.\n\nalternatively, a negative space filler can be used in the layout to make “blank” images (see row 3).\n\nImages must have the same group to appear in the same lightbox.\n\nRow 1:\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nRow 2:\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nRow 3:"
  },
  {
    "objectID": "data/n3_region-builder/note.html",
    "href": "data/n3_region-builder/note.html",
    "title": "ADAM SHAND",
    "section": "",
    "text": "This is a placeholder to ensure the folder is uploaded to GitHub."
  },
  {
    "objectID": "data/dt_maps_fish/note.html",
    "href": "data/dt_maps_fish/note.html",
    "title": "ADAM SHAND",
    "section": "",
    "text": "This is a placeholder to ensure the folder is uploaded to GitHub."
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "ADAM SHAND",
    "section": "",
    "text": "Document\n\n\n\n  \n    \n      \n    \n      Download Current CV"
  },
  {
    "objectID": "data/dt_maps_impoundment-length/note.html",
    "href": "data/dt_maps_impoundment-length/note.html",
    "title": "ADAM SHAND",
    "section": "",
    "text": "This is a placeholder to ensure the folder is uploaded to GitHub."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, Im Adam.",
    "section": "",
    "text": "Document\n\n\n\n  \n    \n      Hi, Im Adam.\n      An environmental data analyst decoding nature's secrets.\n      \n      \n       With experience in R, Tableau, SQL and GIS, I transform raw environmental data into meaningful narratives with stunning visuals. From crafting data-driven solutions to fostering sustainability, I am dedicated to bridging the gap between technology and the environment."
  },
  {
    "objectID": "projects/chronicals_of_the_bay/index.html",
    "href": "projects/chronicals_of_the_bay/index.html",
    "title": "The Chronicals of Cleveland Bay",
    "section": "",
    "text": "Corals of Cleveland Bay\n\n\n\nTo be released in March 2024, the Corals of Cleveland Bay StoryMap will unveil the hidden world of coral reefs beneath the surface of Cleveland Bay.\n\n\n\n\n\n\n\n\nHydrology and Hydrodynamics of Cleveland Bay\n\n\n\nReleased in November 2023, the Hydrology and Hydrodynamics of Cleveland Bay StoryMap focus on the movement of water in and around the Bay:\nRain comes in massive peaks and troughs, cyclones tear across the ocean, and winds and currents stir the coast into a swirling mix of salt, sand, and sediment. The  Hydrology and Hydrodynamics of Cleveland Bay story explores, from the very beginnings, the journey of water across Cleveland Bay: where it comes from, where it goes, what it does, and how it does it. It explores the impact of humans on water, what impacts are yet to come, and how we can best prepare for the future.\n\n\n\n\n\n\n\n\nGuardians of the Bay\n\n\n\nReleased in March 2022, the Guardians of the Bay StoryMap explores the importance of seagrass for our daily lives.\nSeagrass, small plants with a big impact. The  Guardians of the Bay  story explores how seagrass can stabilize the ocean floor, improve water quality, and protect our shores from erosion, it takes you on a journey under the ocean and into the flourishing world of seagrass in Cleveland Bay."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Environmental Bytes for a Better Earth",
    "section": "",
    "text": "Document\n\n\n  \n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nAn Opinionated Dataframe Cleaner\n\n\nNaming your dataframe columns doesn’t have to be hard, does it? Here I demonstrate the benefits of implimenting an opionated dataframe cleaner to help keep your columns…\n\n\n\n\n\n\n04 Jan, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Chronicals of Cleveland Bay\n\n\nESRI StoryMaps about Cleveland Bay.\n\n\n\n\n\n\n01 Mar, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConquering Environmental Reporting Using R\n\n\nMapping my environmental spatial analysis workflow in R.\n\n\n\n\n\n\n02 Jan, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Artificial Intelligence for Automatic Fish Detection from Acoustic Cameras\n\n\nMy first ever journal publication! What a journey.\n\n\n\n\n\n\n26 May, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "presentations/index.html",
    "href": "presentations/index.html",
    "title": "Environmental Bytes for a Better Earth",
    "section": "",
    "text": "Document\n\n\n  \n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/out_of_the_shadows - Copy (2)/index.html",
    "href": "projects/out_of_the_shadows - Copy (2)/index.html",
    "title": "Using Artificial Intelligence for Automatic Fish Detection from Acoustic Cameras",
    "section": "",
    "text": "Tip\n\n\n\n Out of the shadows: automatic fish detection from acoustic cameras:  Efficacious monitoring of fish stocks is critical for efficient management. Multibeam acoustic cameras, that use sound-reflectance to generate moving pictures, provide an important alternative to traditional video-based methods that are inoperable in turbid waters. However, acoustic cameras, like standard video monitoring methods, produce large volumes of imagery from which it is time consuming and costly to extract data manually. Deep learning, a form of machine learning, can be used to automate the processing and analysis of acoustic data. We used convolutional neural networks (CNNs) to detect and count fish in a publicly available dual-frequency identification sonar (DIDSON) dataset. We compared three types of detections, direct acoustic, acoustic shadows, and a combination of direct and shadows. The deep learning model was highly reliable at detecting fish to obtain abundance data using acoustic data. Model accuracy for counts-per-image was improved by the inclusion of shadows (F1 scores, a measure of the model accuracy: direct 0.79, shadow 0.88, combined 0.90). Model accuracy for MaxN per video was high for all three types of detections (F1 scores: direct 0.90, shadow 0.90, combined 0.91). Our results demonstrate that CNNs are a powerful tool for automating underwater acoustic data analysis. Given this promise, we suggest broadening the scope of testing to include a wider range of fish shapes, sizes, and abundances, with a view to automating species (or ‘morphospecies’) identification and counts."
  },
  {
    "objectID": "projects/conquering_reports_with_r - Copy (2)/index.html",
    "href": "projects/conquering_reports_with_r - Copy (2)/index.html",
    "title": "Conquering Environmental Reporting Using R",
    "section": "",
    "text": "Tip\n\n\n\n Work-In-Progress, no current link. \nThis is currently a work in progress stored on a private repository on GitHub. The project has been written for the Dry Tropics Partnership for Healthy Waters, and can be considered my most important body of work thus far. Below is a schematic overview of the repository."
  },
  {
    "objectID": "projects/chronicals_of_the_bay - Copy (2)/index.html",
    "href": "projects/chronicals_of_the_bay - Copy (2)/index.html",
    "title": "The Chronicals of Cleveland Bay",
    "section": "",
    "text": "Corals of Cleveland Bay\n\n\n\nTo be released in March 2024, the Corals of Cleveland Bay StoryMap will unveil the hidden world of coral reefs beneath the surface of Cleveland Bay.\n\n\n\n\n\n\n\n\nHydrology and Hydrodynamics of Cleveland Bay\n\n\n\nReleased in November 2023, the Hydrology and Hydrodynamics of Cleveland Bay StoryMap focus on the movement of water in and around the Bay:\nRain comes in massive peaks and troughs, cyclones tear across the ocean, and winds and currents stir the coast into a swirling mix of salt, sand, and sediment. The  Hydrology and Hydrodynamics of Cleveland Bay story explores, from the very beginnings, the journey of water across Cleveland Bay: where it comes from, where it goes, what it does, and how it does it. It explores the impact of humans on water, what impacts are yet to come, and how we can best prepare for the future.\n\n\n\n\n\n\n\n\nGuardians of the Bay\n\n\n\nReleased in March 2022, the Guardians of the Bay StoryMap explores the importance of seagrass for our daily lives.\nSeagrass, small plants with a big impact. The  Guardians of the Bay  story explores how seagrass can stabilize the ocean floor, improve water quality, and protect our shores from erosion, it takes you on a journey under the ocean and into the flourishing world of seagrass in Cleveland Bay."
  },
  {
    "objectID": "projects/chronicals_of_the_bay - Copy/index.html",
    "href": "projects/chronicals_of_the_bay - Copy/index.html",
    "title": "The Chronicals of Cleveland Bay",
    "section": "",
    "text": "Corals of Cleveland Bay\n\n\n\nTo be released in March 2024, the Corals of Cleveland Bay StoryMap will unveil the hidden world of coral reefs beneath the surface of Cleveland Bay.\n\n\n\n\n\n\n\n\nHydrology and Hydrodynamics of Cleveland Bay\n\n\n\nReleased in November 2023, the Hydrology and Hydrodynamics of Cleveland Bay StoryMap focus on the movement of water in and around the Bay:\nRain comes in massive peaks and troughs, cyclones tear across the ocean, and winds and currents stir the coast into a swirling mix of salt, sand, and sediment. The  Hydrology and Hydrodynamics of Cleveland Bay story explores, from the very beginnings, the journey of water across Cleveland Bay: where it comes from, where it goes, what it does, and how it does it. It explores the impact of humans on water, what impacts are yet to come, and how we can best prepare for the future.\n\n\n\n\n\n\n\n\nGuardians of the Bay\n\n\n\nReleased in March 2022, the Guardians of the Bay StoryMap explores the importance of seagrass for our daily lives.\nSeagrass, small plants with a big impact. The  Guardians of the Bay  story explores how seagrass can stabilize the ocean floor, improve water quality, and protect our shores from erosion, it takes you on a journey under the ocean and into the flourishing world of seagrass in Cleveland Bay."
  },
  {
    "objectID": "projects/conquering_reports_with_r - Copy/index.html",
    "href": "projects/conquering_reports_with_r - Copy/index.html",
    "title": "Conquering Environmental Reporting Using R",
    "section": "",
    "text": "Tip\n\n\n\n Work-In-Progress, no current link. \nThis is currently a work in progress stored on a private repository on GitHub. The project has been written for the Dry Tropics Partnership for Healthy Waters, and can be considered my most important body of work thus far. Below is a schematic overview of the repository."
  },
  {
    "objectID": "projects/out_of_the_shadows - Copy/index.html",
    "href": "projects/out_of_the_shadows - Copy/index.html",
    "title": "Using Artificial Intelligence for Automatic Fish Detection from Acoustic Cameras",
    "section": "",
    "text": "Tip\n\n\n\n Out of the shadows: automatic fish detection from acoustic cameras:  Efficacious monitoring of fish stocks is critical for efficient management. Multibeam acoustic cameras, that use sound-reflectance to generate moving pictures, provide an important alternative to traditional video-based methods that are inoperable in turbid waters. However, acoustic cameras, like standard video monitoring methods, produce large volumes of imagery from which it is time consuming and costly to extract data manually. Deep learning, a form of machine learning, can be used to automate the processing and analysis of acoustic data. We used convolutional neural networks (CNNs) to detect and count fish in a publicly available dual-frequency identification sonar (DIDSON) dataset. We compared three types of detections, direct acoustic, acoustic shadows, and a combination of direct and shadows. The deep learning model was highly reliable at detecting fish to obtain abundance data using acoustic data. Model accuracy for counts-per-image was improved by the inclusion of shadows (F1 scores, a measure of the model accuracy: direct 0.79, shadow 0.88, combined 0.90). Model accuracy for MaxN per video was high for all three types of detections (F1 scores: direct 0.90, shadow 0.90, combined 0.91). Our results demonstrate that CNNs are a powerful tool for automating underwater acoustic data analysis. Given this promise, we suggest broadening the scope of testing to include a wider range of fish shapes, sizes, and abundances, with a view to automating species (or ‘morphospecies’) identification and counts."
  },
  {
    "objectID": "projects/an_opinionated_dataframe_cleaner/index.html",
    "href": "projects/an_opinionated_dataframe_cleaner/index.html",
    "title": "An Opinionated Dataframe Cleaner",
    "section": "",
    "text": "Introduction\nInconsistent and illogical naming conventions can ruin even the best analysts flow, cause sneaky errors, and potentially lead to misleading or completely incorrect results. Throughout my time as an environmental data analyst I have come across countless instances where the names used in a dataframe mess up my analysis, and I can guarantee I’m not the only one. Just Google “the importance of file naming” to find countless monologues (just like this one), or “bad naming conventions” to realize, actually it could be worse!\nSo if this is such a widely acknowledged issue, why is it still an issue? How has it not been fixed? Simply put, because a) its boring, and b) everyone is unique and has their own idea of what a “good” system looks like. This leads to people not bothering, or instances where you might pull together several datasets from a range of sources, each using their own (different) naming conventions. Thankfully, if each dataset is at least internally consistent, we can address these differences.\nBelow, I introduce my method of addressing this issue. It is a highly opinionated dataframe cleaner that focuses exclusively on ensuring every dataframe I touch receives exactly the same column naming convention. Before we dive it, I believe it is critical to recognise that this method is customized to my needs, it may work for you as well, but I recommend instead that you use this as inspiration to develop your own method.\n\n\nThe Naming Convention\nSo what naming convention am I using exactly? “Upper Camel Case” is my choice, however some people may also refer to it as “Pascal Case”. If your are unfamiliar, here are some examples of naming conventions:\n\nUpperCamelCase\nsnake_case\nkebab-case\nUPPERFLATCASE\netc.\n\nWhy UpperCamelCase? As noted above, everyone has their own idea of what is good. I find that upper camel case suite my purposes well, it is fairly easy to read, it only contains A-Z, 0-9 (no underscores or dashes), and most importantly it does not class with my object names when coding it R. What I mean by this is that I use snake_case to name my objects, and UpperCamelCase to name columns within my objects. Lets consider the following example.\nLets say I have a dataframe that counts fish:\n\n\nCode\nlibrary(dplyr)\n\nfish &lt;- data.frame(fish = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                   fish_count_location_1 = c(6,9,3,5,10),\n                   fish_count_location_2 = c(1,16,3,2,7))\n\nhead(fish)\n\n\n  fish fish_count_location_1 fish_count_location_2\n1    A                     6                     1\n2    B                     9                    16\n3    C                     3                     3\n4    D                     5                     2\n5    E                    10                     7\n\n\n(Note that both the object and column names are in snake_case).\nThen I decide to figure out the mean number of each species of fish, across all locations:\n\n\nCode\nmean_fish &lt;- fish |&gt; \n  group_by(fish) |&gt; \n  mutate(mean_fish = mean(fish_count_location_1, fish_count_location_2)) |&gt; \n  ungroup()\n\nhead(mean_fish)\n\n\n# A tibble: 5 × 4\n  fish  fish_count_location_1 fish_count_location_2 mean_fish\n  &lt;chr&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;     &lt;dbl&gt;\n1 A                         6                     1         6\n2 B                         9                    16         9\n3 C                         3                     3         3\n4 D                         5                     2         5\n5 E                        10                     7        10\n\n\nWhoops, just by using some logical naming I now accidentally have a dataframe object named “mean_fish”, and a column within that dataframe named “mean_fish”. Now obviously this is a silly example, but image we have 1000+ lines of code, suddenly we can’t remember whats an object and whats a column.\nThus; my final reason for choosing UpperCamelCase:\n\n\nCode\nfish &lt;- data.frame(Fish = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                   FishCountLocation1 = c(6,9,3,5,10),\n                   FishCountLocation2 = c(1,16,3,2,7))\n\nmean_fish &lt;- fish |&gt; \n  group_by(Fish) |&gt; \n  mutate(MeanFish = mean(FishCountLocation1, FishCountLocation2)) |&gt; \n  ungroup()\n\nhead(mean_fish)\n\n\n# A tibble: 5 × 4\n  Fish  FishCountLocation1 FishCountLocation2 MeanFish\n  &lt;chr&gt;              &lt;dbl&gt;              &lt;dbl&gt;    &lt;dbl&gt;\n1 A                      6                  1        6\n2 B                      9                 16        9\n3 C                      3                  3        3\n4 D                      5                  2        5\n5 E                     10                  7       10\n\n\n\n\nThe Function\nMy custom function takes advantage of the janitor R package, which includes a wide range of functions to perform standard cleaning and organisation steps (check out the janitor documentation to see what it can do). Specifically, we are going to use the clean_names() function, along with some bells and whistles to catch our edge cases. Lets take a look:\n\n\nCode\n#create the custom function\nname_cleaning &lt;- function(df){\n\n  #open the core libraries of this function\n  library(janitor)\n  library(dplyr)\n  library(sf)\n  \n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n    \n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n    \n    #extract the geometry column as it own object\n    extract_geom_col &lt;- st_geometry(df)\n    \n    #bind the column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = extract_geom_col) |&gt; \n      st_as_sf()\n  \n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n  \n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n  \n  return(df_new)\n  \n}\n\n\nOk, so even though that is a relatively short function, there is still a few things going on. Lets break it down a bit.\n\nFirst we will initialize the function (if you are unfamiliar with creating your own functions check out my other post).\n\n\n\nCode\n#initialize the function\nname_cleaning &lt;- function(df){\n\n\n\nThen we load each of our required packages. Noting that generally we would expect this packages to already have been loaded in by the script calling this function, but we can’t be sure.\n\n\n\nCode\n  #open the core libraries of this function\n  library(janitor)\n  library(dplyr)\n  library(sf)\n\n\n\nWe then check if the dataframe we are cleaning is actually an “sf” object. Sf objects are special types of dataframes using in geospatial analytics that have an extra column containing coordinate information. This special column has its own rules for column naming and therefore sf objects should be handled differently.\n\n\n\nCode\n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n\n\n\nIf we are looking at an sf object, we copy the sf object and remove the geometry column from this copy. Following this, we can then run janitor’s clean_names() function.\n\n\n\nCode\n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n\n\nWhile also extracting just the geometry column into a separate object.\n\n\nCode\n    #extract the geometry column as it own object\n    extract_geom_col &lt;- st_geometry(df)\n    \n    #bind the column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = extract_geom_col) |&gt; \n      st_as_sf()\n  \n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n  \n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n  \n  return(df_new)\n  \n}\n\n\nOverview - dataframes often have strange naming conventions, everyone is different, sometimes within a df there is no consistency - these column names can be difficult to work with, particularly when using regex - they can also be confusing when working with objects (object names) - There are R packages written to help with this, such as janitor - I have developed a function using janitor that instill highly opinionated naming - It is opinionated in that it is what I think is best, and works with my repositories. It is not meant to be globally applicable for everyone (but maybe you can learn something) - Lets have a look\n\n\nCode\n#inputs: \n#df &lt;- every single df that is read should be passed through this function\n\nname_cleaning &lt;- function(df){\n\n  #open the core libraries of this function\n  library(janitor)\n  library(dplyr)\n  library(sf)\n  \n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n    \n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n    TRUE\n    \n    #extract the geometry column as it own object\n    extract_geom_col &lt;- st_geometry(df)\n    \n    #bind the column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = extract_geom_col) |&gt; \n      st_as_sf()\n  \n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n  \n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n  \n  return(df_new)\n  \n}\n\n\n\n\nCode\ncolnames(iris)\n\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\n\n\nCode\ncolnames(name_cleaning(iris))\n\n\n[1] \"SepalLength\" \"SepalWidth\"  \"PetalLength\" \"PetalWidth\"  \"Species\""
  }
]