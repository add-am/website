[
  {
    "objectID": "posts/an_opinionated_dataframe_cleaner/index.html",
    "href": "posts/an_opinionated_dataframe_cleaner/index.html",
    "title": "An Opinionated Dataframe Cleaner",
    "section": "",
    "text": "Introduction\nInconsistent and illogical naming conventions can ruin even the best analysts flow, cause sneaky errors, and potentially lead to misleading or completely incorrect results. Throughout my time as an environmental data analyst I have come across countless instances where the names used in a dataframe mess up my analysis, and I can guarantee I’m not the only one. Just Google “the importance of file naming” to find countless monologues (just like this one), or “bad naming conventions” to realize, actually it could be worse!\nSo if this is such a widely acknowledged issue, why is it still an issue? How has it not been fixed? Simply put, because a) its boring, and b) everyone is unique and has their own idea of what a “good” system looks like. This leads to people not bothering, or instances where you might pull together several datasets from a range of sources, each using their own (different) naming conventions. Thankfully, if each dataset is at least internally consistent, we can address these differences.\nBelow, I introduce my method of addressing this issue. It is a highly opinionated dataframe cleaner that focuses exclusively on ensuring every dataframe I touch receives exactly the same column naming convention. Before we dive it, I believe it is critical to recognise that this method is customized to my needs, it may work for you as well, but I recommend instead that you use this as inspiration to develop your own method.\n\n\nThe Naming Convention\nSo what naming convention am I using exactly? “Upper Camel Case” is my choice, however some people may also refer to it as “Pascal Case”. If your are unfamiliar, here are some examples of naming conventions:\n\nUpperCamelCase\nsnake_case\nkebab-case\nUPPERFLATCASE\netc.\n\nWhy UpperCamelCase? As noted above, everyone has their own idea of what is good. I find that upper camel case suite my purposes well, it is fairly easy to read, it only contains A-Z, 0-9 (no underscores or dashes), and most importantly it does not clash with my object names when coding it R. What I mean by this is that I use snake_case to name my objects, and UpperCamelCase to name columns within my objects. Lets consider the following example.\nLets say I have a dataframe that counts fish (called “fish”):\n\n\nCode\n#load the dplyr package\nlibrary(dplyr)\n\n#create an example dataframe\nfish &lt;- data.frame(species = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                   fish_count_location_1 = c(6,9,3,5,10),\n                   fish_count_location_2 = c(1,16,3,2,7))\n\n#print the dataframe. If you want to learn about this function, check out my pretty tables post!\ncond_form_tables(fish)\n\n\n\n\nspeciesfish_count_location_1fish_count_location_2\n\nA61\n\nB916\n\nC33\n\nD52\n\nE107\n\n\n\n\n(Note that both the object and column names are in snake_case).\nThen I decide to figure out the mean number of each species of fish, across all locations (called “mean_fish”):\n\n\nCode\n#get the rowwise mean of the fish counts per species\nmean_fish &lt;- fish |&gt; \n  rowwise() |&gt; \n  mutate(mean_fish = mean(c(fish_count_location_1, fish_count_location_2))) |&gt; \n  ungroup()\n\n#print the dataframe\ncond_form_tables(mean_fish)\n\n\n\n\nspeciesfish_count_location_1fish_count_location_2mean_fish\n\nA613.5\n\nB91612.5\n\nC333  \n\nD523.5\n\nE1078.5\n\n\n\n\nWhoops, just by using some logical naming I now accidentally have a dataframe object named “mean_fish”, and a column within that dataframe named “mean_fish”. Now obviously this is a silly example, but image we have 1000+ lines of code, and we need to know something about the mean number of fish. Suddenly we can’t remember whats an object and whats a column and we can run into subtle errors, or have very confusing lines of codes.\nThus; my final reason for choosing UpperCamelCase:\n\n\nCode\n#create a new example dataframe\nfish &lt;- data.frame(Species = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                   FishCountLocation1 = c(6,9,3,5,10),\n                   FishCountLocation2 = c(1,16,3,2,7))\n\n#get the rowwise mean of the fish counts per species\nmean_fish &lt;- fish |&gt; \n  rowwise() |&gt; \n  mutate(mean_fish = mean(c(FishCountLocation1, FishCountLocation2))) |&gt; \n  ungroup()\n\n#print the dataframe\ncond_form_tables(mean_fish)\n\n\n\n\nSpeciesFishCountLocation1FishCountLocation2mean_fish\n\nA613.5\n\nB91612.5\n\nC333  \n\nD523.5\n\nE1078.5\n\n\n\n\n\n\nThe Function\nMy custom function takes advantage of the janitor R package, which includes a wide range of functions to perform standard cleaning and organisation steps (check out the janitor documentation to see what it can do). Specifically, we are going to use the clean_names() function, along with some bells and whistles to catch our edge cases. Lets take a look:\n\n\nCode\n#create the custom function\nname_cleaning &lt;- function(df){\n\n  #load and install (if required) the pacman package handler package, which we will use for all future package downloads\n  if(!require(\"pacman\")){install.packages(\"pacman\")}\n\n  #use the pacman function to load and install (if required) all other packages\n  pacman::p_load(janitor, dplyr, sf, stringr)\n\n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n    \n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n    \n    #bind the geometry column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = st_geometry(df)) |&gt; \n      st_as_sf()\n  \n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n  \n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n  \n  return(df_new)\n  \n}\n\n\nOk, so even though that is a relatively short function, there is still a few things going on. Lets break it down a bit.\n\nFirst we will initialize the function (if you are unfamiliar with creating your own functions check out my functions post).\n\n\n\nCode\n#initialize the function\nname_cleaning &lt;- function(df){\n\n\n\nThen we load each of our required packages. Noting that generally we would expect these packages to already have been loaded in by the script calling this function, but we can’t be sure. Here we use the pacman package to make the install/load steps a bit more streamline, documentation for pacman can be found here.\n\n\n\nCode\n  #load and install (if required) the pacman package handler package, which we will use for all future package downloads\n  if(!require(\"pacman\")){install.packages(\"pacman\")}\n\n  #use the pacman function to load and install (if required) all other packages\n  pacman::p_load(janitor, dplyr, sf, stringr)\n\n\n\nWe then check if the dataframe we are cleaning is actually an “sf” object. Sf objects are special types of dataframes using in geospatial analytics that have an extra column containing coordinate information. This special column has its own rules for column naming and therefore sf objects should be handled differently. In my work I encounter sf bjects very often.\n\n\n\nCode\n  #check if the df is an sf object and if so, apply clean names to every column but the last column\n  if(inherits(df, \"sf\")){\n\n\n\nIf we are looking at an sf object, we copy the sf object and remove the geometry column from this copy. Following this, we can then run janitor’s clean_names() function on the copy with no geometry column. The reason we do this is that the janitor package has no precedent for sf objects. In the clean_names() function, we specify that we want the column names to follow the “upper_camel” format. This will convert all our column names to the desired format.\n\n\n\nCode\n    #convert all but the geometry column to upper camel type\n    df_new &lt;- df |&gt; \n      st_drop_geometry() |&gt;\n      clean_names(case = \"upper_camel\")\n\n\n\nOnce we have cleaned the names of every column in the SF object, we can the add the special geometry column back on to the dataset. At this point we also need to convert the object back to the “SF” type.\n\n\n\n\n\n\n\nNote\n\n\n\nYou may notice that this special geometry column is called “geom” rather than “Geom”… which doesn’t adhere to our naming convention. Unfortunately, this is an annoying quirk of spatial datasets. When they are loaded, the geometry column can take on 1 of 3 different names depending on the source of the data; “geom”, “geometry”, or “shape”. In all cases the name is lowercase, even when the data is saved in uppercase, it will be reloaded in lowercase. Thus, for this issue, we simply ensure that the 3 different possibilities are all just converted to the “geom” option.\n\n\n\n\nCode\n    #bind the geometry column back on with its new name. Note that it should also be named \"geom\"\n    df_new &lt;- df_new |&gt;\n      dplyr::mutate(geom = st_geometry(df)) |&gt; \n      st_as_sf()\n\n\n\nIf the object is a simple dataframe (not an sf object), we can just move straight to the clean_names() step that we explained above.\n\n\n\nCode\n  } else {\n    \n    #convert ALL columns to upper camel type, don't have to worry about geometry\n    df_new &lt;- df |&gt; \n      clean_names(case = \"upper_camel\")\n    \n  }\n\n\n\nNext we look to catch strange edge cases related to the encoding column of columns. You are likely familiar with the concept of a column being of type “character” or “numeric” or “boolean”, etc. Our strange edge case is similar to this. What we have found is that in some instances the character column type is encoded as “UTF-8”, while other times it is encoded as “ASCII”. Much like how you can’t combine character and numeric columns, you also can’t combine columns encoded as UTF-8 and ASCII. Below we convert all columns encoded as UTF-8 to ASCII to avoid this issue.\n\n\n\n\n\n\n\nNote\n\n\n\nPlease note that these encodings are hidden from the user and you will never normally need to interact with them, the reason this happens doesn’t matter, and is frankly some mysterious property of excel. Broadly, you probably don’t need to ever understand why/how this step works.\n\n\n\n\nCode\n  #for every character type column, run a encoding check and fix, then remove weird new line characters\n  df_new &lt;- df_new  |&gt; \n    mutate(across(where(is.character), ~ iconv(., from = 'UTF-8', to = 'ASCII//TRANSLIT'))) |&gt; \n    mutate(across(where(is.character), ~str_replace_all(., \"\\r\\n\", \" \")))\n\n\n\nThe object is then returned and the function is complete.\n\n\n\nCode\n  return(df_new)\n  \n}\n\n\n\n\nIn Practice\nNow that we understand how the function works, lets demonstrate its use with another example dataset that has a wide range of column names. Here is before:\n\n\nCode\n#create an example table with example names\nexample_df &lt;- data.frame(\"column 1\" = c(1,2,3,4,5),\n                         \"column-2\" = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                         \"column_3\" = c(NA, NA, NA, NA, NA),\n                         \"column-four\" = c(\"1A\", \"2B\", \"3C\", \"4D\", \"5E\"),\n                         \"Column Five\" = c(TRUE, FALSE, TRUE, FALSE, TRUE))\n\n#print the table\nprint(example_df)\n\n\n  column.1 column.2 column_3 column.four Column.Five\n1        1        A       NA          1A        TRUE\n2        2        B       NA          2B       FALSE\n3        3        C       NA          3C        TRUE\n4        4        D       NA          4D       FALSE\n5        5        E       NA          5E        TRUE\n\n\nAnd after:\n\n\nCode\n#run the clean name functions\nexample_df_cleaned &lt;- name_cleaning(example_df)\n\n#print the cleaned dataset\ncond_form_tables(example_df_cleaned)\n\n\n\n\nColumn1Column2Column3ColumnFourColumnFive\n\n1A1ATRUE\n\n2B2BFALSE\n\n3C3CTRUE\n\n4D4DFALSE\n\n5E5ETRUE\n\n\n\n\n\n\nCaveats\nIt is also important to acknowledge the caveats of your own work. To my knowledge the only caveat of this function is that it relies on a sensible preexisting column name, even if the format is horrible. What I mean by this is that a column named “Mean-fish_in Townsville” can be cleaned, but a column with no name… well how can you rename that to something appropriate? As a side note R does generally replace empty column names with “X1”, “X2”, etc. however this still does not provide any information about the column."
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "ADAM SHAND",
    "section": "",
    "text": "Document\n\n\n\n  \n    \n      \n    \n      Download Current CV"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, Im Adam.",
    "section": "",
    "text": "Document\n\n\n\n  \n    \n      Hi, Im Adam.\n      An environmental data analyst decoding nature's secrets.\n      \n      \n       With experience in R, Tableau, SQL and GIS, I transform raw environmental data into meaningful narratives with stunning visuals. From crafting data-driven solutions to fostering sustainability, I am dedicated to bridging the gap between technology and the environment."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Environmental Bytes for a Better Earth",
    "section": "",
    "text": "Document\n\n\n  \n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nAn Opinionated Dataframe Cleaner\n\n\n\n\n\nNaming your dataframe columns doesn’t have to be hard, does it? Here I demonstrate the benefits of implimenting an opionated dataframe cleaner to help keep your columns organised.\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLearning To Create Your Own Custom Functions\n\n\n\n\n\nTBD.\n\n\n\n\n\n04 Jan, 2025\n\n\n\n\n\n\nNo matching items"
  }
]